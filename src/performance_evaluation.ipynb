{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephenzhang/Documents/code/feature-engineering/feature-engineering/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from data.load_credit_data import load_credit_data\n",
    "from config import TARGET_COL, DEFAULT_FEATURES, ID_COLS, CAT_COLS\n",
    "from feature_engineering.imputations import knn_impute\n",
    "from classification_methods.classification_methods import lgbm_classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephenzhang/Documents/code/feature-engineering/src/data/load_credit_data.py:22: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (100000, 28), Test shape: (50000, 27)\n",
      "Target column: Credit_Mix\n",
      "[LGBM] Dropping non-numeric columns: ['Month', 'Age', 'Annual_Income']\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.666074\n",
      "[LightGBM] [Info] Start training from score -1.408387\n",
      "[LightGBM] [Info] Start training from score -1.007926\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "Imputed Data - Test Accuracy: 0.5606\n",
      "[LGBM] Dropping non-numeric columns: ['Month', 'Age', 'Annual_Income']\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 509\n",
      "[LightGBM] [Info] Number of data points in the train set: 67998, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.660392\n",
      "[LightGBM] [Info] Start training from score -1.413576\n",
      "[LightGBM] [Info] Start training from score -1.009159\n",
      "[LightGBM] [Info] Start training from score -1.598803\n",
      "Non-Imputed Data - Test Accuracy: 0.5744\n"
     ]
    }
   ],
   "source": [
    "train = load_credit_data('train.csv')\n",
    "test = load_credit_data('test.csv')\n",
    "print(f'Train shape: {train.shape}, Test shape: {test.shape}')\n",
    "\n",
    "# 2. Define target column\n",
    "target_col = TARGET_COL\n",
    "print(f'Target column: {target_col}')\n",
    "\n",
    "# Features for LGBM (exclude ID columns)\n",
    "lgbm_features = DEFAULT_FEATURES.copy()\n",
    "\n",
    "# Features for KNN imputation (include all except target)\n",
    "knn_features = list(set(DEFAULT_FEATURES + CAT_COLS + ID_COLS))\n",
    "if target_col in knn_features:\n",
    "    knn_features.remove(target_col)\n",
    "\n",
    "# Separate numeric and non-numeric columns for KNN imputation\n",
    "numeric_features = train[knn_features].select_dtypes(include='number').columns.tolist()\n",
    "non_numeric_features = [col for col in knn_features if col not in numeric_features]\n",
    "\n",
    "# Impute only numeric columns\n",
    "train_numeric_imputed = knn_impute(train[numeric_features])\n",
    "test_numeric_imputed = knn_impute(test[numeric_features])\n",
    "\n",
    "# Concatenate imputed numeric columns with non-numeric columns\n",
    "train_imputed = pd.concat([\n",
    "    train_numeric_imputed,\n",
    "    train[non_numeric_features].reset_index(drop=True)\n",
    "], axis=1)\n",
    "test_imputed = pd.concat([\n",
    "    test_numeric_imputed,\n",
    "    test[non_numeric_features].reset_index(drop=True)\n",
    "], axis=1)\n",
    "train_imputed[target_col] = train[target_col].values\n",
    "if target_col in test.columns:\n",
    "    test_imputed[target_col] = test[target_col].values\n",
    "\n",
    "# 4. Train LGBM on imputed train data and apply on test\n",
    "X_train_imp = train_imputed[lgbm_features]\n",
    "y_train_imp = train_imputed[target_col]\n",
    "X_test_imp = test_imputed[lgbm_features]\n",
    "model_imp, acc_imp, preds_imp, y_test_imp = lgbm_classification(X_train_imp, y_train_imp)\n",
    "print(f'Imputed Data - Test Accuracy: {acc_imp:.4f}')\n",
    "\n",
    "# 5. Train LGBM on non-imputed train data and apply on test\n",
    "train_dropna = train.dropna(subset=numeric_features + [target_col])\n",
    "X_train_noimp = train_dropna[lgbm_features]\n",
    "y_train_noimp = train_dropna[target_col]\n",
    "model_noimp, acc_noimp, preds_noimp, y_test_noimp = lgbm_classification(X_train_noimp, y_train_noimp)\n",
    "print(f'Non-Imputed Data - Test Accuracy: {acc_noimp:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.59      0.58      0.59      3870\n",
      "        Good       0.69      0.59      0.64      4774\n",
      "    Standard       0.51      0.84      0.63      7281\n",
      "           _       0.14      0.00      0.00      4075\n",
      "\n",
      "    accuracy                           0.56     20000\n",
      "   macro avg       0.48      0.50      0.47     20000\n",
      "weighted avg       0.49      0.56      0.50     20000\n",
      "\n",
      "Non-Imputed Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.59      0.62      0.60      3259\n",
      "        Good       0.70      0.64      0.67      4088\n",
      "    Standard       0.52      0.82      0.64      6245\n",
      "           _       0.05      0.00      0.00      3408\n",
      "\n",
      "    accuracy                           0.57     17000\n",
      "   macro avg       0.47      0.52      0.48     17000\n",
      "weighted avg       0.48      0.57      0.51     17000\n",
      "\n",
      "Imputed Data Confusion Matrix:\n",
      "[[2260    7 1596    7]\n",
      " [  50 2835 1882    7]\n",
      " [ 737  413 6113   18]\n",
      " [ 766  827 2477    5]]\n",
      "Non-Imputed Data Confusion Matrix:\n",
      "[[2015    4 1233    7]\n",
      " [  60 2611 1412    5]\n",
      " [ 706  396 5137    6]\n",
      " [ 661  720 2026    1]]\n"
     ]
    }
   ],
   "source": [
    "# 6. Compare basic statistical criteria\n",
    "print('Imputed Data Classification Report:')\n",
    "print(classification_report(y_test_imp, preds_imp))\n",
    "print('Non-Imputed Data Classification Report:')\n",
    "print(classification_report(y_test_noimp, preds_noimp))\n",
    "print('Imputed Data Confusion Matrix:')\n",
    "print(confusion_matrix(y_test_imp, preds_imp))\n",
    "print('Non-Imputed Data Confusion Matrix:')\n",
    "print(confusion_matrix(y_test_noimp, preds_noimp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feature-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
