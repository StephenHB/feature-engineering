{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephenzhang/Documents/code/feature-engineering/feature-engineering/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from data.load_credit_data import load_credit_data\n",
    "from data.auto_feature_grouping import detect_and_adjust_data_schema, group_columns, manually_adjust_input_cols\n",
    "from config import TARGET_COL, DEFAULT_FEATURES, ID_COLS, CAT_COLS\n",
    "from feature_engineering.imputations import knn_impute\n",
    "from classification_methods.classification_methods import lgbm_classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephenzhang/Documents/code/feature-engineering/src/data/load_credit_data.py:22: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (100000, 28), Test shape: (50000, 27)\n",
      "Moved 'Monthly_Balance' from 'id_cols' to 'continuous_cols'.\n",
      "Moved 'Monthly_Balance' from 'id_cols' to 'continuous_cols'.\n",
      "Train column groups: {'id_cols': ['ID', 'Customer_ID', 'Name'], 'date_cols': [], 'continuous_cols': ['Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'Delay_from_due_date', 'Num_Credit_Inquiries', 'Credit_Utilization_Ratio', 'Total_EMI_per_month', 'Monthly_Balance'], 'binary_cols': [], 'categorical_cols': ['Month', 'Age', 'SSN', 'Occupation', 'Annual_Income', 'Num_of_Loan', 'Type_of_Loan', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Credit_Mix', 'Outstanding_Debt', 'Credit_History_Age', 'Payment_of_Min_Amount', 'Amount_invested_monthly', 'Payment_Behaviour', 'Credit_Score'], 'other_cols': []}\n",
      "Test column groups: {'id_cols': ['ID', 'Customer_ID', 'Name'], 'date_cols': [], 'continuous_cols': ['Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'Delay_from_due_date', 'Num_Credit_Inquiries', 'Credit_Utilization_Ratio', 'Total_EMI_per_month', 'Monthly_Balance'], 'binary_cols': [], 'categorical_cols': ['Month', 'Age', 'SSN', 'Occupation', 'Annual_Income', 'Num_of_Loan', 'Type_of_Loan', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Credit_Mix', 'Outstanding_Debt', 'Credit_History_Age', 'Payment_of_Min_Amount', 'Amount_invested_monthly', 'Payment_Behaviour'], 'other_cols': []}\n"
     ]
    }
   ],
   "source": [
    "train = load_credit_data('train.csv')\n",
    "test = load_credit_data('test.csv')\n",
    "train, _ = detect_and_adjust_data_schema(train)\n",
    "test, _ = detect_and_adjust_data_schema(test)\n",
    "print(f'Train shape: {train.shape}, Test shape: {test.shape}')\n",
    "\n",
    "train_groups = group_columns(train)\n",
    "test_groups = group_columns(test)\n",
    "change_cols = {'current_col': \"id_cols\", \"new_col\": \"continuous_cols\", \"val\": \"Monthly_Balance\"}\n",
    "train_groups = manually_adjust_input_cols(train_groups, change)\n",
    "test_groups = manually_adjust_input_cols(test_groups, change)\n",
    "print(\"Train column groups:\", train_groups)\n",
    "print(\"Test column groups:\", test_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target column: Credit_Mix\n"
     ]
    }
   ],
   "source": [
    "# 2. Define target column  and imputation features\n",
    "target_col = TARGET_COL\n",
    "print(f'Target column: {target_col}')\n",
    "imputation_features = [\"Monthly_Balance\"]\n",
    "# Determine LGBM features\n",
    "if train_groups is not None:\n",
    "    # Flatten all values from train_groups except those in imputation_features\n",
    "    all_grouped_features = [item for sublist in train_groups.values() for item in sublist]\n",
    "    lgbm_features = [f for f in all_grouped_features if f not in imputation_features]\n",
    "else:\n",
    "    lgbm_features = [f for f in DEFAULT_FEATURES if f not in imputation_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Dropping non-numeric columns: ['ID', 'Customer_ID', 'Name', 'Month', 'Age', 'SSN', 'Occupation', 'Annual_Income', 'Num_of_Loan', 'Type_of_Loan', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Outstanding_Debt', 'Credit_History_Age', 'Payment_of_Min_Amount', 'Amount_invested_monthly', 'Payment_Behaviour', 'Credit_Score']\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1854\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.666074\n",
      "[LightGBM] [Info] Start training from score -1.408387\n",
      "[LightGBM] [Info] Start training from score -1.007926\n",
      "[LightGBM] [Info] Start training from score -1.601966\n",
      "Imputed Data - Test Accuracy: 0.7194\n",
      "[LGBM] Dropping non-numeric columns: ['ID', 'Customer_ID', 'Name', 'Month', 'Age', 'SSN', 'Occupation', 'Annual_Income', 'Num_of_Loan', 'Type_of_Loan', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Outstanding_Debt', 'Credit_History_Age', 'Payment_of_Min_Amount', 'Amount_invested_monthly', 'Payment_Behaviour', 'Credit_Score']\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1853\n",
      "[LightGBM] [Info] Number of data points in the train set: 66652, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.655445\n",
      "[LightGBM] [Info] Start training from score -1.419735\n",
      "[LightGBM] [Info] Start training from score -1.008680\n",
      "[LightGBM] [Info] Start training from score -1.596944\n",
      "Non-Imputed Data - Test Accuracy: 0.7235\n"
     ]
    }
   ],
   "source": [
    "# Features for KNN imputation (include all except target)\n",
    "knn_features = lgbm_features\n",
    "if target_col in knn_features:\n",
    "    knn_features.remove(target_col)\n",
    "\n",
    "# Separate numeric and non-numeric columns for KNN imputation\n",
    "numeric_features = train[knn_features].select_dtypes(include='number').columns.tolist()\n",
    "non_numeric_features = [col for col in knn_features if col not in numeric_features]\n",
    "\n",
    "# Impute only numeric columns\n",
    "train_numeric_imputed = knn_impute(train[numeric_features])\n",
    "test_numeric_imputed = knn_impute(test[numeric_features])\n",
    "\n",
    "# Concatenate imputed numeric columns with non-numeric columns\n",
    "train_imputed = pd.concat([\n",
    "    train_numeric_imputed,\n",
    "    train[non_numeric_features].reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# Remove target_col from non_numeric_features for test set and filter only columns present in test\n",
    "non_numeric_features_test = [col for col in non_numeric_features if col in test.columns and col != target_col]\n",
    "test_imputed = pd.concat([\n",
    "    test_numeric_imputed,\n",
    "    test[non_numeric_features_test].reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "train_imputed[target_col] = train[target_col].values\n",
    "if target_col in test.columns:\n",
    "    test_imputed[target_col] = test[target_col].values\n",
    "\n",
    "# 4. Train LGBM on imputed train data and apply on test\n",
    "# Filter lgbm_features to only those present in train_imputed and test_imputed\n",
    "lgbm_features_train = [f for f in lgbm_features if f in train_imputed.columns]\n",
    "lgbm_features_test = [f for f in lgbm_features if f in test_imputed.columns]\n",
    "X_train_imp = train_imputed[lgbm_features_train]\n",
    "y_train_imp = train_imputed[target_col]\n",
    "X_test_imp = test_imputed[lgbm_features_test]\n",
    "model_imp, acc_imp, preds_imp, y_test_imp = lgbm_classification(X_train_imp, y_train_imp)\n",
    "print(f'Imputed Data - Test Accuracy: {acc_imp:.4f}')\n",
    "\n",
    "# 5. Train LGBM on non-imputed train data and apply on test\n",
    "train_dropna = train.dropna(subset=numeric_features + [target_col])\n",
    "X_train_noimp = train_dropna[lgbm_features_train]\n",
    "y_train_noimp = train_dropna[target_col]\n",
    "model_noimp, acc_noimp, preds_noimp, y_test_noimp = lgbm_classification(X_train_noimp, y_train_noimp)\n",
    "print(f'Non-Imputed Data - Test Accuracy: {acc_noimp:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.69      0.97      0.81      3870\n",
      "        Good       0.74      0.90      0.81      4774\n",
      "    Standard       0.73      0.87      0.79      7281\n",
      "           _       0.19      0.00      0.00      4075\n",
      "\n",
      "    accuracy                           0.72     20000\n",
      "   macro avg       0.59      0.69      0.60     20000\n",
      "weighted avg       0.61      0.72      0.64     20000\n",
      "\n",
      "Non-Imputed Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.69      0.97      0.81      3142\n",
      "        Good       0.75      0.90      0.82      4114\n",
      "    Standard       0.73      0.87      0.79      6097\n",
      "           _       0.15      0.00      0.00      3311\n",
      "\n",
      "    accuracy                           0.72     16664\n",
      "   macro avg       0.58      0.69      0.61     16664\n",
      "weighted avg       0.61      0.72      0.65     16664\n",
      "\n",
      "Imputed Data Confusion Matrix:\n",
      "[[3769    0   94    7]\n",
      " [   0 4305  464    5]\n",
      " [ 612  345 6307   17]\n",
      " [1110 1167 1791    7]]\n",
      "Non-Imputed Data Confusion Matrix:\n",
      "[[3048    0   89    5]\n",
      " [   0 3700  404   10]\n",
      " [ 474  291 5301   31]\n",
      " [ 899  930 1474    8]]\n"
     ]
    }
   ],
   "source": [
    "# 6. Compare basic statistical criteria\n",
    "print('Imputed Data Classification Report:')\n",
    "print(classification_report(y_test_imp, preds_imp))\n",
    "print('Non-Imputed Data Classification Report:')\n",
    "print(classification_report(y_test_noimp, preds_noimp))\n",
    "print('Imputed Data Confusion Matrix:')\n",
    "print(confusion_matrix(y_test_imp, preds_imp))\n",
    "print('Non-Imputed Data Confusion Matrix:')\n",
    "print(confusion_matrix(y_test_noimp, preds_noimp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feature-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
